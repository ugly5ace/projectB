# Сверточнйы слой сердце CNN (convolutional layer):
#Жтро осноной строительный блок сети представьте что у вас есть сспециальныйц детектор который ищет определенный узор
# на изобрадении например вертикальный линию край или спаециифческую текстуру
# фильтр ядро свертки кернел
# этро наш детектор или трафарет фильтр это небольшая матрица чисел например 3х3 5х5 эти числа вес афильтпа подбираются в
# процессе обучпения сети так тчобы фильтр наилучшим образом реагировал на определнный визуальный признак границы кглы текстуры цвета

# карта признаков (feature map)
# результат скольжения одгого фильтра по вспму входному изображению это по сути нова якартинка которая полсвесчивает те области
# гле фильтр нашел свой специфический признак чем сильнее отклик тем ярче это место на карте признаков

# Stride (шаг)
# это параметр определяющий на сколько пикселей фильтр смещается за один раз скользя по изображению если шаг равен 1 фильтр
#перемешается на 1 пиксль аналогия представьте что вы читаете текст stride 1 вы читааете каждую ьукву
# stride 2 вы читаете через букву

# padding дополнение
# представьте что наш фильтр трафарет должен обработать края изобраджения если ничего не прелпринять пиксели по краям будут
# участвовать в меньшем количестве вычислений чем пиксели в центре чтобы это оисправить и чтобы разер карты признаков не уменьшаося
# слишкром быстро ( или сохранялся тем же что и входное изображкние при stride 1 по краям изображения добавляются дополнительные
# пиксели обычно это нулевые пиксели (zero-padding)
# zero-padding stride 1


# 2 слой активации (Activation layer) добавляем нелинейность
# после того как сверточный слой вычеслил силу различных признаков в разных частях изображения нам нужно решить какие из этих
# сигналов достаточно важны чтобы передать их дальше здесь на сцену выходит слой активации после свертки (Или любого другого слоя
# вычисляющего взвещенную сумму)
# используптся функцими активации ее главная задача внести нелинейность в модел



# Самая популярная функция активации в CNN это (rectified Linear Unit)
#  она обнуляет все отрицательные значения оставляя положительны без изменений

# 3 слой подвыборки (pooling layer / subsampling) уменьшаем и обобщаем

# 4 полносвязный слой (fully connected layer / dense layer):
# после тогго как несколько сверточчныз и пулинг слоев ищвлекли из изобрадения набор высокоуровневнызх признаков
# например есть что то похожее на колесо вижу текстуру шерсти эти признакм нужно как то обьединить чтобы принять окончательные решение о том что изабредно
# на картинке

# компьюьтерном зрение это облать в котором модели  CNN применяются для анализа изображений или видео с помощью  CNN можно решать
# следующие задачи
# классификациыя обьектов (Object detection)
# сегментация изображений

from tensorflow.keras import layers, models
from tensorflow.keras.datasets import cifar10
from tensorflow.keras.utils import to_categorical
import matplotlib.pyplot as plt #
from tensorflow.python.keras.saving.saved_model.serialized_attributes import metrics

(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()


num_classes = 10
class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']

plt.figure(figsize=(10,10))
for i in range(25):
    plt.subplot(5,5,i+1)
    plt.xticks([])
    plt.yticks([])
    plt.grid(False)
    plt.imshow(train_images[i])
    plt.xlabel(class_names[train_labels[i][0]])
plt.show()

# normalize данных
# значения пикселей в изобрвжениях обычно находятся в диапазоне 0 255
# для нейроненых сетей лучше когда взодные данные нррмализованы
# те привелены к небольшому диапазону например 0 1
# это помогает ускорить оьучнеи и улучшить стабильность

train_images_normalized = train_images.astype('float32') / 255
test_images_normalized = train_images.astype('float32') / 255

# преобразование меток в категориальной формат (ван хот инкодинг)
# наши метки траин_лабелс тест_лабелс) это числа от 0 до 9
# для задачи классификации с функцией потерь категориал_кроссентропай
# метки должны быть представлены в формате ван хот например если метка 4 олень она стане вектором
#[0,0,0,0,1,0,0,0,0] если олень 4й инлекмс полсе 0
# [0,0,0,0,1,0,0,0,0]
# 7 [0,0,0,0,0,0,1,0,0]
# 9 [0,0,0,0,0,0,0,0,1]

train_images_cat = to_categorical(train_labels, num_classes)
test_labels_cat = to_categorical(test_labels, num_classes)

# CNN model
model = models.Sequential()
# first сверточный блок Conv2D + MaxPooling2D
# *Conv2D(32, (3,3), ...): 32 - это количество фильтров (или карт признаков)
#которые мы хотим получить
# 3,3 размер каждого фильтра ядра светки
# activation='relu' : применяем ReLu активацию после свертки
# уменьшался после свертки при страйд 1
# input_shape=(32,32,3): указываем форму входного изображения толькро для первого слоя

model.add(layers.Conv2D(32, (3,3), activation='relui', input_shape=(32,32,3)))
model.add(layers.MaxPooling2D((2,2)))
#MaxPooling2D уменьшаем размер карты признаков в 2 раза по каждой оси выбирая максимальное значение
model.add(layers.Conv2D(64, (3,3), activation='relu', padding='same'))
model.add(layers.MaxPooling2D((2,2)))

#3
model.add(layers.Conv2D(128, (3,3), activation='relu', padding='same'))
model.add(layers.MaxPooling2D((2,2)))

# после последнего MaxPool слоя наши карты признаков будут иметь размер например 4х4х128
# (32 - 16 - 8 - 4 по каждой из пространственных осей) Теперь их нужно выпрямить в один длинный вектор для подачи на
# полносвязанные слои
model.add(layers.Flatten())

# dense128
#
model.add(layers.Dense(128, activation='relu'))

# выходной слов
# dense количество нейронов равно количеству классов 10 для СИФАР10
# activation='softmax': Softmax преобращзует вызодлы в вероятности для каждого класса ё
model.add(layers.Dense(num_classes, activation='softmax'))

# компиляция модели
# optimizer='adam' : Adam - хороший универсальный и жффективный алгоритм оптимищзации
# loss='categorical-crossentropy'
#metrics= ['accuracy']
model.compile(optimizer='adam',
              loss='categorical_crossentropy')
metrics=['accuracy']

print("\nНачало обучения модели...")
history = model.fit(train_images_normalized, train_labels_cat,
                    epochs=15,
                    batch_size=64,
                    validation_data=(test_images_normalized, test_labels_cat))
print("Обучение завершено")

#